{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80af9482",
   "metadata": {},
   "source": [
    "<H1>COMP4531 Deep Learning Mid-Term</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53f9bc",
   "metadata": {},
   "source": [
    "In this project, we will be developing a basic neural network from the ground up to classify various types of fashion items. The primary objective of this project is to gain a comprehensive understanding of neural network architecture, including its theory and implementation details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f36f4",
   "metadata": {},
   "source": [
    "<H2>Part 0: Initialization</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da766f3",
   "metadata": {},
   "source": [
    "To start, let's load some packages and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that you don't need any other packages for this mid-term\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "random.seed(42) # NEVER change this line; this is for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "data = pd.read_csv('./fashion_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data pre-processing is done for you. Please do NOT edit the cell\n",
    "# However, you should understand what these codes are doing\n",
    "\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:400].T\n",
    "Y_dev = data_dev[-1]\n",
    "X_dev = data_dev[0:n-1]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[400:m].T\n",
    "Y_train = data_train[-1]\n",
    "X_train = data_train[0:n-1]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec10f7",
   "metadata": {},
   "source": [
    "<H2>Part 1: Building your own neural network</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a070079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a global variable specifying the number of hidden neurons after the first layer\n",
    "# not the best practice, but we will do it for this mid-term project\n",
    "num_hidden_neurons = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f133d",
   "metadata": {},
   "source": [
    "This is the main part of the mid-term. You **must not** change the definition of the function. In fact, the comments are going to help you go through the implementation and they are all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ec06a",
   "metadata": {},
   "source": [
    "<H3>1.1 Initialize the parameter in the neural network</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa30c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters in the neural network\n",
    "\n",
    "# Based on the figure above, we need the weight and bias matrices. \n",
    "# W1, b1 are the matrices for the first layer\n",
    "# W2, b2 are the matrices for the second layer\n",
    "\n",
    "# You should think about the sizes of the matrices\n",
    "# then initialize elements in the matrix to be random numbers between -0.5 to +0.5\n",
    "\n",
    "def init_params():\n",
    "    W1 = # Your code here\n",
    "    b1 = # Your code here\n",
    "    W2 = # Your code here\n",
    "    b2 = # Your code here\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e02886",
   "metadata": {},
   "source": [
    "<H3>1.2 Implement the non-linearity functions and its derivatives</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fec893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a starting point, you only need a ReLu function, its derivative, and the softmax function \n",
    "\n",
    "def ReLU(Z):\n",
    "    # Your code here\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    # Your code here\n",
    "\n",
    "def softmax(Z):\n",
    "    # Your code here\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e8de8",
   "metadata": {},
   "source": [
    "<H3>1.3 Implement the forward propagation function</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the forward propagation function, X is the inputs (the image in vector form), and we pass all the weights and biases\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = # Your code here\n",
    "    A1 = # Your code here\n",
    "    Z2 = # Your code here\n",
    "    A2 = # Your code here\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc732fd3",
   "metadata": {},
   "source": [
    "<H3>1.4 Implement the backward propagation function</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60edcfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one hot function is to convert a numeric number into a one-hot vector\n",
    "def one_hot(Y):\n",
    "    # Your code here\n",
    "    return one_hot_Y\n",
    "\n",
    "# Now performing the backward propagation\n",
    "# Each function is only one line, but lots of Calculus behind \n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = # Your code here\n",
    "    dW2 = # Your code here\n",
    "    db2 = # Your code here\n",
    "    dZ1 = # Your code here\n",
    "    dW1 = # Your code here\n",
    "    db1 = # Your code here\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Finally, we are ready to update the parameters\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = # Your code here\n",
    "    b1 = # Your code here\n",
    "    W2 = # Your code here\n",
    "    b2 = # Your code here  \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa112e7c",
   "metadata": {},
   "source": [
    "<H3>1.5 Performing the gradient descent</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the helper function. We need to convert the softmax output into a numeric label \n",
    "# This is done through get_predictions function\n",
    "def get_predictions(A2):\n",
    "    # Your code here\n",
    "\n",
    "# We also want to have a simple function to compute the accuracy. Notice that \"predictions\" and \"Y\" are the same shape\n",
    "def get_accuracy(predictions, Y):\n",
    "    return # Your code here\n",
    "\n",
    "# Finally, we are ready to implement gradient descent\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = # Your code here - using the function you have implemented\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = # Your code here - using the function you have implemented\n",
    "        dW1, db1, dW2, db2 = # Your code here - using the function you have implemented\n",
    "        W1, b1, W2, b2 = # Your code here - using the function you have implemented\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98227fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fd141",
   "metadata": {},
   "source": [
    "<H3>1.6 Validation Set Performance</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83cd53",
   "metadata": {},
   "source": [
    "<H3>1.7 Exploring some samples</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa50dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "test_prediction(0, W1, b1, W2, b2)\n",
    "test_prediction(1, W1, b1, W2, b2)\n",
    "test_prediction(2, W1, b1, W2, b2)\n",
    "test_prediction(50, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489e39c",
   "metadata": {},
   "source": [
    "<H2>Part 2: Error Analysis and Performance Improvements</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b9c4e",
   "metadata": {},
   "source": [
    "Based on the neural network, you should recommend some next steps in this part. Some ideas include investigating where the model fails to predict and/or trying to improve the model performance through, for example, different activation functions, expanding the network complexity.\n",
    "\n",
    "**It is crucial to provide reasoning behind what you do, or else no credit will be given.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
